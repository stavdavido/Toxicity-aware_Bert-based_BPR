{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0da8f2-bdf3-42db-a321-24684f1eb781",
   "metadata": {},
   "source": [
    "Load the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a11058-beae-4b64-adc1-88d99f774b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "notes = pd.read_csv(\n",
    "    r'...\\NOTEEVENTS.csv.gz',\n",
    "    dtype={4: str, 5: str}  # or int, float, etc. depending on data\n",
    ")\n",
    "\n",
    "notes = notes[notes[\"CATEGORY\"].isin([\"Discharge summary\"])]\n",
    "notes = notes.dropna(subset=[\"TEXT\", \"HADM_ID\"])\n",
    "\n",
    "patient_texts = notes.groupby(\"HADM_ID\")[\"TEXT\"].apply(lambda x: \"\\n\".join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66172fb0-fa80-4e10-9150-ed405081b510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final note embedding shape: (52726, 768)\n"
     ]
    }
   ],
   "source": [
    "# Ensure consistent ID type\n",
    "patient_texts['HADM_ID'] = patient_texts['HADM_ID'].astype(str)\n",
    "\n",
    "# Load clinical note embeddings\n",
    "loaded = np.load(r'...\\useremb.npz')\n",
    "clinical_embs = loaded['array1']  # shape: (n_users, emb_dim)\n",
    "\n",
    "projected_note_embs = []\n",
    "\n",
    "for i, subj_id in enumerate(patient_texts['HADM_ID']):\n",
    "    clinical_emb = clinical_embs[i]\n",
    "    \n",
    "    projected_note_embs.append(clinical_emb)\n",
    "\n",
    "projected_note_embs = np.array(projected_note_embs)\n",
    "print(f\"Final note embedding shape: {projected_note_embs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169a8e05-d073-41a8-a6ab-e465d01b3835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class EmbeddingProjector(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.ReLU(),  # Optional: or GELU, Tanh\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80a365b-7e1e-48eb-a907-794be69fac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "combined_tensor = torch.tensor(projected_note_embs, dtype=torch.float32)\n",
    "\n",
    "# Project to original dimension (or any size)\n",
    "input_dim = combined_tensor.shape[1]\n",
    "output_dim = 128 \n",
    "projector = EmbeddingProjector(input_dim, output_dim)\n",
    "\n",
    "# Forward pass (no training yet)\n",
    "with torch.no_grad():\n",
    "    projected_tensor = projector(combined_tensor)\n",
    "\n",
    "# Convert back to NumPy if needed for Cornac\n",
    "projected_note_embs = projected_tensor.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a0456b-8a55-405c-85d4-1b36bdbb77cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52726, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_note_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ae7026-46b7-4591-a733-bf79667097a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_embeddings = np.load(r'...\\drug_embeddings.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8724f090-20ab-49e2-a5c9-9d855fcd492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Convert to tensor\n",
    "combined_tensor = torch.tensor(drug_embeddings, dtype=torch.float32)\n",
    "\n",
    "# Project to original dimension (or any size)\n",
    "input_dim = combined_tensor.shape[1]\n",
    "output_dim = 128\n",
    "projector = EmbeddingProjector(input_dim, output_dim)\n",
    "\n",
    "# Forward pass (no training yet)\n",
    "with torch.no_grad():\n",
    "    projected_tensor = projector(combined_tensor)\n",
    "\n",
    "# Convert back to NumPy if needed for Cornac\n",
    "projected_drug_embeddings = projected_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d89bc2a-2b7d-40a7-a5a1-122411797923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_drug_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a6af2-335b-4c17-b7c8-4f7332e5f59e",
   "metadata": {},
   "source": [
    "Safety Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d7b819b-d016-43fb-a6d0-be441582fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac.metrics import RankingMetric\n",
    "\n",
    "class DDIRate(RankingMetric):\n",
    "    def __init__(self, ddi_matrix, k=10, name=\"DDI@10\"):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - ddi_pairs: set of (drug_id_1, drug_id_2) tuples indicating known DDIs.\n",
    "        - k: number of top predicted items to consider per user.\n",
    "        \"\"\"\n",
    "        super().__init__(name=name, k=k)\n",
    "        self.ddi_matrix = ddi_matrix\n",
    "\n",
    "    def compute(self, gt_pos, gt_neg, pd_rank, pd_scores, item_indices=None):\n",
    "        top_k_items = pd_rank[:self.k]\n",
    "        ddi_count = 0\n",
    "        total_pairs = 0\n",
    "\n",
    "        for i in range(len(top_k_items)):\n",
    "            for j in range(i + 1, len(top_k_items)):\n",
    "                d1, d2 = top_k_items[i], top_k_items[j]    \n",
    "                if frozenset({d1, d2}) in self.ddi_matrix or frozenset({d2, d1}) in self.ddi_matrix:\n",
    "                    ddi_count += 1\n",
    "                total_pairs += 1\n",
    "\n",
    "        ddi_rate = ddi_count / total_pairs if total_pairs > 0 else 0.0\n",
    "        return ddi_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6ddfbf-b821-4c23-a4c0-84d4ef23828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "class ToxicityDDIRate(RankingMetric):\n",
    "    def __init__(self, toxicity_matrix, k=10, name=\"ToxicityDDI@10\"):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - toxicity_matrix: 2D NumPy array or sparse matrix where toxicity_matrix[i, j] \n",
    "                           gives the toxicity score of the DDI between drugs i and j.\n",
    "                           (0 if no interaction, >0 if interaction exists)\n",
    "        - k: number of top predicted items to consider per user.\n",
    "        \"\"\"\n",
    "        super().__init__(name=name, k=k)\n",
    "        self.toxicity_matrix = toxicity_matrix\n",
    "\n",
    "    def compute(self, gt_pos, gt_neg, pd_rank, pd_scores, item_indices=None):\n",
    "        top_k_items = pd_rank[:self.k]\n",
    "        if len(top_k_items) < 2:\n",
    "            return 0.0\n",
    "\n",
    "        # All unordered pairs among top-k\n",
    "        pairs = np.array(list(combinations(top_k_items, 2)))\n",
    "\n",
    "        # Sum toxicity of interactions among top-k items\n",
    "        toxicity_sum = self.toxicity_matrix[pairs[:, 0], pairs[:, 1]].sum()\n",
    "        total_pairs = len(pairs)\n",
    "\n",
    "        return toxicity_sum / total_pairs if total_pairs > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dea32b3-8a1c-478b-a9eb-ee2a44a9ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r'...\\mapped_ddi_pairs.pkl', 'rb') as f:\n",
    "    mapped_ddi_pairs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0380c62-27a3-4630-9d3b-313df514678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('clomipramine', 'itraconazole', 'minor')\n"
     ]
    }
   ],
   "source": [
    "print(mapped_ddi_pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73653937-5403-405f-8c0c-665c43d3b6be",
   "metadata": {},
   "source": [
    "TBBPR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54df76ac-c582-4f9e-95b6-0e2a7750519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from tqdm.auto import trange\n",
    "from cornac.models import Recommender\n",
    "from cornac.utils.init_utils import uniform, zeros\n",
    "\n",
    "\n",
    "def normalize_rows(mat):\n",
    "    \"\"\"Row-wise L2 normalization.\"\"\"\n",
    "    norms = np.linalg.norm(mat, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1\n",
    "    return mat / norms\n",
    "\n",
    "\n",
    "class TBBPR(Recommender):\n",
    "    \"\"\"\n",
    "    MultiTask BPR with:\n",
    "    - Pretrained patient/drug embeddings\n",
    "    - Optional DDI toxicity multitask loss (vectorized)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # pretrained\n",
    "        patient_embeddings=None,\n",
    "        drug_embeddings=None,\n",
    "        fold_uid_map=None,\n",
    "        fold_iid_map=None,\n",
    "        residual_scale=0.01,\n",
    "        # multitask BPR\n",
    "        k=50,\n",
    "        max_iter=100,\n",
    "        learning_rate=0.01,\n",
    "        lambda_reg=0.001,\n",
    "        alpha=0.8,\n",
    "        ddi_pairs=None,\n",
    "        # misc\n",
    "        verbose=False,\n",
    "        seed=None,\n",
    "    ):\n",
    "        super().__init__(name=\"TBBPR\", trainable=True, verbose=verbose)\n",
    "\n",
    "        # embedding dim (override if pretrained provided)\n",
    "        self.k = (\n",
    "            patient_embeddings.shape[1]\n",
    "            if patient_embeddings is not None\n",
    "            else (drug_embeddings.shape[1] if drug_embeddings is not None else k)\n",
    "        )\n",
    "\n",
    "        # store pretrained + maps\n",
    "        self.patient_embeddings = (\n",
    "            normalize_rows(patient_embeddings) if patient_embeddings is not None else None\n",
    "        )\n",
    "        self.drug_embeddings = (\n",
    "            normalize_rows(drug_embeddings) if drug_embeddings is not None else None\n",
    "        )\n",
    "        self.fold_uid_map = fold_uid_map or {}\n",
    "        self.fold_iid_map = fold_iid_map or {}\n",
    "\n",
    "        self.residual_scale = residual_scale\n",
    "\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.alpha = alpha\n",
    "        self.ddi_pairs = ddi_pairs if ddi_pairs is not None else []\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "\n",
    "\n",
    "        # save params for clone\n",
    "        self._init_params = copy.deepcopy(locals())\n",
    "        self._init_params.pop(\"self\")\n",
    "\n",
    "    def _init_factors(self, train_set):\n",
    "        # ---- users ----\n",
    "        self.u_factors = (uniform((train_set.num_users, self.k),\n",
    "                                  random_state=self.rng,\n",
    "                                  dtype=np.float32) - 0.5) / self.k\n",
    "        covered_users = 0\n",
    "        if self.patient_embeddings is not None and self.fold_uid_map:\n",
    "            for uid in range(train_set.num_users):\n",
    "                raw_uid = train_set.user_ids[uid]\n",
    "                if raw_uid in self.fold_uid_map:\n",
    "                    emb_idx = self.fold_uid_map[raw_uid]\n",
    "                    base = self.patient_embeddings[emb_idx]\n",
    "                    if not np.allclose(base, 0):\n",
    "                        covered_users += 1\n",
    "                    self.u_factors[uid] = base + self.residual_scale * (\n",
    "                        uniform((1, self.k), random_state=self.rng, dtype=np.float32) - 0.5\n",
    "                    ) / self.k\n",
    "        if self.verbose:\n",
    "            print(f\"Users with pretrained emb: {covered_users}/{train_set.num_users}\")\n",
    "\n",
    "        # ---- items ----\n",
    "        self.i_factors = (uniform((train_set.num_items, self.k),\n",
    "                                  random_state=self.rng,\n",
    "                                  dtype=np.float32) - 0.5) / self.k\n",
    "        covered_items = 0\n",
    "        if self.drug_embeddings is not None and self.fold_iid_map:\n",
    "            for iid in range(train_set.num_items):\n",
    "                raw_iid = train_set.item_ids[iid].lower().strip()\n",
    "                if raw_iid in self.fold_iid_map:\n",
    "                    emb_idx = self.fold_iid_map[raw_iid]\n",
    "                    base = self.drug_embeddings[emb_idx]\n",
    "                    if not np.allclose(base, 0):\n",
    "                        covered_items += 1\n",
    "                    self.i_factors[iid] = base + self.residual_scale * (\n",
    "                        uniform((1, self.k), random_state=self.rng, dtype=np.float32) - 0.5\n",
    "                    ) / self.k\n",
    "        if self.verbose:\n",
    "            print(f\"Items with pretrained emb: {covered_items}/{train_set.num_items}\")\n",
    "\n",
    "        # biases\n",
    "        self.i_biases = zeros(train_set.num_items, dtype=np.float32)\n",
    "\n",
    "    def _prepare_data(self, train_set):\n",
    "        X = train_set.matrix\n",
    "        user_counts = np.ediff1d(X.indptr)\n",
    "        user_ids = np.repeat(np.arange(train_set.num_users), user_counts)\n",
    "        return X, user_counts, user_ids\n",
    "\n",
    "    def fit(self, train_set, val_set=None):\n",
    "        super().fit(train_set, val_set)\n",
    "        self._init_factors(train_set)\n",
    "        X, _, user_ids = self._prepare_data(train_set)\n",
    "        neg_item_ids = np.arange(train_set.num_items, dtype=np.int32)\n",
    "\n",
    "        with trange(self.max_iter, disable=not self.verbose) as progress:\n",
    "            for epoch in progress:\n",
    "                correct, skipped = self._fit_sgd(user_ids, X.indices, X.indptr, neg_item_ids)\n",
    "                if self.verbose:\n",
    "                    progress.set_postfix({\n",
    "                        \"correct\": \"%.2f%%\" % (100.0 * correct / (len(user_ids) - skipped)),\n",
    "                        \"skipped\": \"%.2f%%\" % (100.0 * skipped / len(user_ids))\n",
    "                    })\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def _fit_sgd(self, user_ids, item_ids, indptr, neg_item_ids):\n",
    "        item_id_set = set(item_ids)\n",
    "\n",
    "        # filter DDI pairs\n",
    "        if self.ddi_pairs:\n",
    "            filtered = [(d1, d2, sev) for d1, d2, sev in self.ddi_pairs\n",
    "                        if d1 in item_id_set and d2 in item_id_set]\n",
    "            if filtered:\n",
    "                d1_idx, d2_idx, sev_vals = zip(*filtered)\n",
    "                d1_idx, d2_idx, sev_vals = map(np.array, (d1_idx, d2_idx, sev_vals))\n",
    "            else:\n",
    "                d1_idx = d2_idx = sev_vals = np.array([])\n",
    "        else:\n",
    "            d1_idx = d2_idx = sev_vals = np.array([])\n",
    "\n",
    "        # neg items per user\n",
    "        user_neg_sets = {}\n",
    "        for u in np.unique(user_ids):\n",
    "            start, end = indptr[u], indptr[u + 1]\n",
    "            user_neg_sets[u] = np.array(list(set(neg_item_ids) - set(item_ids[start:end])))\n",
    "\n",
    "        # pos/neg triplets\n",
    "        u_array, i_array, j_array = [], [], []\n",
    "        for u in np.unique(user_ids):\n",
    "            pos_items = item_ids[indptr[u]:indptr[u + 1]]\n",
    "            neg_items = user_neg_sets[u]\n",
    "            n_samples = len(pos_items)\n",
    "            if n_samples == 0:\n",
    "                continue\n",
    "            u_array.extend([u] * n_samples)\n",
    "            i_array.extend(pos_items)\n",
    "            j_array.extend(self.rng.choice(neg_items, size=n_samples, replace=True))\n",
    "        u_array, i_array, j_array = map(np.array, (u_array, i_array, j_array))\n",
    "\n",
    "\n",
    "        # --- BPR forward ---\n",
    "        x_ui = self.i_biases[i_array] + np.sum(self.u_factors[u_array] * self.i_factors[i_array], axis=1)\n",
    "        x_uj = self.i_biases[j_array] + np.sum(self.u_factors[u_array] * self.i_factors[j_array], axis=1)\n",
    "        x_uij = x_ui - x_uj\n",
    "        z = 1.0 / (1.0 + np.exp(x_uij))\n",
    "        correct = np.sum(z < 0.5)\n",
    "        skipped = 0        \n",
    "        \n",
    "        # --- BPR updates ---\n",
    "        grad_u = z[:, None] * (self.i_factors[i_array] - self.i_factors[j_array]) - self.lambda_reg * self.u_factors[u_array]\n",
    "        grad_i = z[:, None] * self.u_factors[u_array] - self.lambda_reg * self.i_factors[i_array]\n",
    "        grad_j = -z[:, None] * self.u_factors[u_array] - self.lambda_reg * self.i_factors[j_array]\n",
    "\n",
    "        np.add.at(self.u_factors, u_array, self.learning_rate * self.alpha * grad_u)\n",
    "        np.add.at(self.i_factors, i_array, self.learning_rate * self.alpha * grad_i)\n",
    "        np.add.at(self.i_factors, j_array, self.learning_rate * self.alpha * grad_j)\n",
    "        np.add.at(self.i_biases, i_array, self.learning_rate * self.alpha * (z - self.lambda_reg * self.i_biases[i_array]))\n",
    "        np.add.at(self.i_biases, j_array, self.learning_rate * self.alpha * (-z - self.lambda_reg * self.i_biases[j_array]))\n",
    "\n",
    "        # --- DDI toxicity updates ---\n",
    "        if d1_idx.size > 0:\n",
    "            prod = np.sum(self.i_factors[d1_idx] * self.i_factors[d2_idx], axis=1) - sev_vals\n",
    "            grad_d1 = prod[:, None] * self.i_factors[d2_idx]\n",
    "            grad_d2 = prod[:, None] * self.i_factors[d1_idx]\n",
    "            self.i_factors[d1_idx] -= self.learning_rate * (1 - self.alpha) * grad_d1\n",
    "            self.i_factors[d2_idx] -= self.learning_rate * (1 - self.alpha) * grad_d2\n",
    "\n",
    "        return correct, skipped\n",
    "\n",
    "    def score(self, user_idx, item_idx=None):\n",
    "        if item_idx is None:\n",
    "            scores = np.copy(self.i_biases)\n",
    "            scores += self.u_factors[user_idx] @ self.i_factors.T\n",
    "            return scores\n",
    "        else:\n",
    "            return self.i_biases[item_idx] + self.u_factors[user_idx] @ self.i_factors[item_idx]\n",
    "\n",
    "    def _get_init_params(self):\n",
    "        return copy.deepcopy(self._init_params)\n",
    "\n",
    "    def clone(self, new_params=None):\n",
    "        import inspect\n",
    "        params = copy.deepcopy(self._init_params)\n",
    "        if new_params:\n",
    "            params.update(new_params)\n",
    "        init_params = inspect.signature(self.__init__).parameters\n",
    "        filtered_params = {k: v for k, v in params.items() if k in init_params}\n",
    "        return self.__class__(**filtered_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b114772f-0801-48c2-8467-b6e7c25e6aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 44239 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example DDI pair (internal ids): (814, 438, 1.0)\n",
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 36302 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Training data:\n",
      "Number of users = 15162\n",
      "Number of items = 1122\n",
      "Number of ratings = 367245\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 15162\n",
      "Number of items = 1122\n",
      "Number of ratings = 44305\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 506 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Validation data:\n",
      "Number of users = 15162\n",
      "Number of items = 1122\n",
      "Number of ratings = 44305\n",
      "---\n",
      "Total users = 15162\n",
      "Total items = 1122\n",
      "\n",
      "[MultiTaskEnhancedBPR] Training started!\n",
      "Users with pretrained emb: 14930/15162\n",
      "Items with pretrained emb: 454/1122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4ef7bc0aac485dae57069faafccac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faffb349344486395b3a2f545135c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/13756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 36299 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Training data:\n",
      "Number of users = 15162\n",
      "Number of items = 1116\n",
      "Number of ratings = 367247\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 15162\n",
      "Number of items = 1116\n",
      "Number of ratings = 44305\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 500 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Validation data:\n",
      "Number of users = 15162\n",
      "Number of items = 1116\n",
      "Number of ratings = 44305\n",
      "---\n",
      "Total users = 15162\n",
      "Total items = 1116\n",
      "\n",
      "[MultiTaskEnhancedBPR] Training started!\n",
      "Users with pretrained emb: 14930/15162\n",
      "Items with pretrained emb: 450/1116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d86e95da8243b89852a35bd16c8119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956970c5a47a4853a33e0a8ac9d1478d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/13807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 36363 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Training data:\n",
      "Number of users = 15161\n",
      "Number of items = 1129\n",
      "Number of ratings = 367184\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 15161\n",
      "Number of items = 1129\n",
      "Number of ratings = 44296\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 521 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Validation data:\n",
      "Number of users = 15161\n",
      "Number of items = 1129\n",
      "Number of ratings = 44296\n",
      "---\n",
      "Total users = 15161\n",
      "Total items = 1129\n",
      "\n",
      "[MultiTaskEnhancedBPR] Training started!\n",
      "Users with pretrained emb: 14929/15161\n",
      "Items with pretrained emb: 451/1129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79515d6258e74e13a7a55b2183f3554c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed04c7144cf54fc78fefe818df857f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/13753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 36479 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Training data:\n",
      "Number of users = 15160\n",
      "Number of items = 1104\n",
      "Number of ratings = 367068\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 15160\n",
      "Number of items = 1104\n",
      "Number of ratings = 44287\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 502 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Validation data:\n",
      "Number of users = 15160\n",
      "Number of items = 1104\n",
      "Number of ratings = 44287\n",
      "---\n",
      "Total users = 15160\n",
      "Total items = 1104\n",
      "\n",
      "[MultiTaskEnhancedBPR] Training started!\n",
      "Users with pretrained emb: 14929/15160\n",
      "Items with pretrained emb: 456/1104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ecb83fd2f240379aa8897f16477f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18577a5eab0f424cbbb14d71efedbdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/13777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 36390 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Training data:\n",
      "Number of users = 15161\n",
      "Number of items = 1127\n",
      "Number of ratings = 367155\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 15161\n",
      "Number of items = 1127\n",
      "Number of ratings = 44303\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 513 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Validation data:\n",
      "Number of users = 15161\n",
      "Number of items = 1127\n",
      "Number of ratings = 44303\n",
      "---\n",
      "Total users = 15161\n",
      "Total items = 1127\n",
      "\n",
      "[MultiTaskEnhancedBPR] Training started!\n",
      "Users with pretrained emb: 14929/15161\n",
      "Items with pretrained emb: 455/1127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d770c905fc974220b64bb483722eaebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8a8c2afb674529909b9ee03f87c3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/13708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 36383 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Training data:\n",
      "Number of users = 15160\n",
      "Number of items = 1118\n",
      "Number of ratings = 367163\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 15160\n",
      "Number of items = 1118\n",
      "Number of ratings = 44311\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 494 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Validation data:\n",
      "Number of users = 15160\n",
      "Number of items = 1118\n",
      "Number of ratings = 44311\n",
      "---\n",
      "Total users = 15160\n",
      "Total items = 1118\n",
      "\n",
      "[MultiTaskEnhancedBPR] Training started!\n",
      "Users with pretrained emb: 14928/15160\n",
      "Items with pretrained emb: 454/1118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87977714392417a87123a9f534de3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd633b143d041049160379d3943ce63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/13730 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 36369 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Training data:\n",
      "Number of users = 15161\n",
      "Number of items = 1117\n",
      "Number of ratings = 367178\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 15161\n",
      "Number of items = 1117\n",
      "Number of ratings = 44295\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 508 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Validation data:\n",
      "Number of users = 15161\n",
      "Number of items = 1117\n",
      "Number of ratings = 44295\n",
      "---\n",
      "Total users = 15161\n",
      "Total items = 1117\n",
      "\n",
      "[MultiTaskEnhancedBPR] Training started!\n",
      "Users with pretrained emb: 14930/15161\n",
      "Items with pretrained emb: 456/1117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21553cd9862e4b60b8f66990e4d74f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4de6b11e0646a1a953ddea81a8615f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/13804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 36353 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Training data:\n",
      "Number of users = 15162\n",
      "Number of items = 1125\n",
      "Number of ratings = 367193\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 15162\n",
      "Number of items = 1125\n",
      "Number of ratings = 44289\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 15162\n",
      "Number of items = 1125\n",
      "Number of ratings = 44289\n",
      "---\n",
      "Total users = 15162\n",
      "Total items = 1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 526 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Training started!\n",
      "Users with pretrained emb: 14930/15162\n",
      "Items with pretrained emb: 455/1125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ca7862a4804feb9dad0bfc3f9e91c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3f8f288e864594b482dc86ce2d9b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/13745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 36312 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Training data:\n",
      "Number of users = 15161\n",
      "Number of items = 1111\n",
      "Number of ratings = 367235\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 15161\n",
      "Number of items = 1111\n",
      "Number of ratings = 44252\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 546 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Validation data:\n",
      "Number of users = 15161\n",
      "Number of items = 1111\n",
      "Number of ratings = 44252\n",
      "---\n",
      "Total users = 15161\n",
      "Total items = 1111\n",
      "\n",
      "[MultiTaskEnhancedBPR] Training started!\n",
      "Users with pretrained emb: 14930/15161\n",
      "Items with pretrained emb: 454/1111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcca65efe354b5cb65721028c0e1fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa32e7f2e0374b3893bfed2adbdcb5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/13736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 36521 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Training data:\n",
      "Number of users = 15161\n",
      "Number of items = 1114\n",
      "Number of ratings = 367026\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 15161\n",
      "Number of items = 1114\n",
      "Number of ratings = 44314\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\medllm\\Lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 483 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Validation data:\n",
      "Number of users = 15161\n",
      "Number of items = 1114\n",
      "Number of ratings = 44314\n",
      "---\n",
      "Total users = 15161\n",
      "Total items = 1114\n",
      "\n",
      "[MultiTaskEnhancedBPR] Training started!\n",
      "Users with pretrained emb: 14929/15161\n",
      "Items with pretrained emb: 450/1114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db507fd56b544c8b010f1c6d8bd60ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MultiTaskEnhancedBPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8dd498d9d540daafbff08375d6aa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/13817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "[MultiTaskEnhancedBPR]\n",
      "       | DDI@10 | NDCG@10 | Recall@10 | SeverityDDI@10 | Train (s) | Test (s)\n",
      "------ + ------ + ------- + --------- + -------------- + --------- + --------\n",
      "Fold 0 | 0.2772 |  0.3506 |    0.4171 |         0.3472 | 5648.4009 |  12.1873\n",
      "Fold 1 | 0.3370 |  0.3511 |    0.4269 |         0.3544 | 5734.8517 |  11.6404\n",
      "Fold 2 | 0.2448 |  0.3455 |    0.4274 |         0.2678 | 5563.9981 |  11.6404\n",
      "Fold 3 | 0.4002 |  0.3493 |    0.4213 |         0.4443 | 5564.0584 |  11.8591\n",
      "Fold 4 | 0.2726 |  0.3535 |    0.4237 |         0.3042 | 5577.8404 |  11.6248\n",
      "Fold 5 | 0.3076 |  0.3514 |    0.4183 |         0.3860 | 5589.0584 |  11.5935\n",
      "Fold 6 | 0.2121 |  0.3572 |    0.4304 |         0.2202 | 5572.1840 |  11.7654\n",
      "Fold 7 | 0.2975 |  0.3505 |    0.4286 |         0.3081 | 5603.2322 |  11.6716\n",
      "Fold 8 | 0.1902 |  0.3564 |    0.4256 |         0.2000 | 5572.8243 |  11.6873\n",
      "Fold 9 | 0.2867 |  0.3574 |    0.4284 |         0.2958 | 5572.7619 |  12.8122\n",
      "------ + ------ + ------- + --------- + -------------- + --------- + --------\n",
      "Mean   | 0.2826 |  0.3523 |    0.4248 |         0.3128 | 5599.9210 |  11.8482\n",
      "Std    | 0.0572 |  0.0036 |    0.0043 |         0.0702 |   50.9813 |   0.3619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Step 0: Imports -------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from rapidfuzz import process\n",
    "import cornac\n",
    "from cornac.data import Dataset\n",
    "from cornac.eval_methods import CrossValidation\n",
    "from cornac.metrics import Recall, NDCG, MRR\n",
    "\n",
    "# ------------------- Step 1: Load Data -------------------\n",
    "ratings_df = pd.read_csv(r\"...\\user_drug_rating_visit_anemia.csv\")\n",
    "matched_df = pd.read_csv(r\"...\\drugbank_mimic_rxcui_map.csv\")\n",
    "\n",
    "# ensure IDs are strings\n",
    "patient_texts['HADM_ID'] = patient_texts['HADM_ID'].astype(float).astype(int).astype(str)\n",
    "\n",
    "# ------------------- Step 2: Clean Drug Names -------------------\n",
    "def clean_drug_name(name):\n",
    "    if pd.isnull(name):\n",
    "        return \"\"\n",
    "    name = name.lower().strip()\n",
    "    name = re.sub(\n",
    "        r\"\\b\\d+(\\.\\d+)?\\s*(mg|ml|mcg|units|tablet|tab|capsule|cap|drop|syrup|patch|ointment|cream|injection|solution|suspension|oral|inj|dose|suppository)\\b\",\n",
    "        \"\",\n",
    "        name,\n",
    "    )\n",
    "    name = re.sub(r\"[^\\w\\s]\", \"\", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "ratings_df.dropna(subset=[\"user\", \"item\", \"rating\"], inplace=True)\n",
    "ratings_df[\"user\"] = ratings_df[\"user\"].astype(str)\n",
    "ratings_df[\"item\"] = ratings_df[\"item\"].astype(str)\n",
    "ratings_df[\"rating\"] = ratings_df[\"rating\"].astype(float)\n",
    "ratings_df[\"clean_item\"] = ratings_df[\"item\"].apply(clean_drug_name)\n",
    "\n",
    "matched_df[\"Generic_Name\"] = matched_df[\"Generic_Name\"].astype(str)\n",
    "matched_df[\"clean_generic\"] = matched_df[\"Generic_Name\"].apply(clean_drug_name)\n",
    "\n",
    "# ------------------- Step 3: Fuzzy Match -------------------\n",
    "ratings_items = ratings_df[\"clean_item\"].unique()\n",
    "mimic_generics = matched_df[\"clean_generic\"].unique().tolist()\n",
    "\n",
    "lookup = {}\n",
    "for item in ratings_items:\n",
    "    match = process.extractOne(item, mimic_generics, score_cutoff=80)\n",
    "    if match:\n",
    "        lookup[item] = match[0]\n",
    "\n",
    "ratings_df[\"matched_generic\"] = ratings_df[\"clean_item\"].map(lookup)\n",
    "ratings_df[\"matched_generic\"] = ratings_df[\"matched_generic\"].fillna(ratings_df[\"clean_item\"])\n",
    "\n",
    "# ------------------- Step 4: Filter Users With Embeddings -------------------\n",
    "subj_id_to_emb_idx = {sid: idx for idx, sid in enumerate(patient_texts[\"HADM_ID\"])}\n",
    "\n",
    "\n",
    "# ------------------- Step 5: Prepare UIR -------------------\n",
    "uir_data = list(zip(ratings_df[\"user\"], ratings_df[\"matched_generic\"], ratings_df[\"rating\"]))\n",
    "cornac_data = Dataset.from_uir(uir_data, seed=123)\n",
    "uid_map = cornac_data.uid_map\n",
    "iid_map = cornac_data.iid_map\n",
    "\n",
    "# ------------------- Step 6: User/Item Embeddings -------------------\n",
    "def align_user_embeddings(cornac_uid_map, raw_to_emb_idx, embeddings):\n",
    "    mat = np.zeros((len(cornac_uid_map), embeddings.shape[1]))\n",
    "    for raw_uid, internal_uid in cornac_uid_map.items():\n",
    "        if raw_uid in raw_to_emb_idx:\n",
    "            mat[internal_uid] = embeddings[raw_to_emb_idx[raw_uid]]\n",
    "    return mat\n",
    "\n",
    "def align_item_embeddings(cornac_iid_map, raw_to_emb_idx, embeddings):\n",
    "    mat = np.zeros((len(cornac_iid_map), embeddings.shape[1]))\n",
    "    for raw_iid, internal_iid in cornac_iid_map.items():\n",
    "        key = raw_iid.lower().strip()\n",
    "        if key in raw_to_emb_idx:\n",
    "            mat[internal_iid] = embeddings[raw_to_emb_idx[key]]\n",
    "    return mat\n",
    "\n",
    "# align embeddings\n",
    "user_emb_matrix = align_user_embeddings(uid_map, subj_id_to_emb_idx, projected_note_embs)\n",
    "drug_id_to_index = {row[\"clean_generic\"]: idx for idx, row in matched_df.iterrows()}\n",
    "item_emb_matrix = align_item_embeddings(iid_map, drug_id_to_index, projected_drug_embeddings)\n",
    "\n",
    "# ------------------- Step 7: Filter DDI Pairs -------------------\n",
    "current_drugs = {drug.lower().strip() for drug in ratings_df[\"matched_generic\"]}\n",
    "filtered_ddi_pairs = [\n",
    "    (d1.lower().strip(), d2.lower().strip(), sev)\n",
    "    for (d1, d2, sev) in mapped_ddi_pairs\n",
    "    if d1.lower().strip() in current_drugs and d2.lower().strip() in current_drugs\n",
    "]\n",
    "\n",
    "# Map raw drug names to internal item indices\n",
    "toxicity_map = {\"minor\": 1.0, \"moderate\": 2.0, \"major\": 3.0}\n",
    "ddi_index_pairs = []\n",
    "for d1, d2, sev in filtered_ddi_pairs:\n",
    "    if d1 in iid_map and d2 in iid_map:\n",
    "        ddi_index_pairs.append((iid_map[d1], iid_map[d2], toxicity_map[sev]))\n",
    "\n",
    "print(\"Example DDI pair (internal ids):\", ddi_index_pairs[0])\n",
    "\n",
    "# ------------------- Step 8: Initialize Model -------------------\n",
    "model = TBBPR(\n",
    "    k=128,\n",
    "    alpha=0.005,\n",
    "    max_iter=1000,\n",
    "    learning_rate=0.001,\n",
    "    ddi_pairs=ddi_index_pairs,\n",
    "    lambda_reg=0.001,\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    patient_embeddings=user_emb_matrix,\n",
    "    drug_embeddings=item_emb_matrix,\n",
    "    fold_uid_map=uid_map,\n",
    "    fold_iid_map=iid_map\n",
    ")\n",
    "\n",
    "# ------------------- Step 9: Setup Evaluation -------------------\n",
    "ratio_split = CrossValidation(\n",
    "    data=uir_data,\n",
    "    n_folds=10,\n",
    "    exclude_unknowns=True,\n",
    "    rating_threshold=1.0,\n",
    "    verbose=True,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "# Create toxicity matrix\n",
    "num_items = len(iid_map)\n",
    "toxicity_matrix = np.zeros((num_items, num_items), dtype=float)\n",
    "for d1, d2, sev in filtered_ddi_pairs:\n",
    "    if d1 in iid_map and d2 in iid_map:\n",
    "        i, j = iid_map[d1], iid_map[d2]\n",
    "        toxicity_matrix[i, j] = toxicity_map[sev]\n",
    "        toxicity_matrix[j, i] = toxicity_map[sev]\n",
    "\n",
    "toxicity_ddi_metric = ToxicityDDIRate(toxicity_matrix=toxicity_matrix, k=10)\n",
    "\n",
    "ddi_index_pairs_set = set()\n",
    "for d1, d2, _ in filtered_ddi_pairs:\n",
    "    if d1 in iid_map and d2 in iid_map:\n",
    "        ddi_index_pairs_set.add(frozenset((iid_map[d1], iid_map[d2])))\n",
    "\n",
    "ddi_metric = DDIRate(ddi_matrix=ddi_index_pairs_set, k=10)\n",
    "\n",
    "eval_metrics = [Recall(k=10), NDCG(k=[10]), toxicity_ddi_metric, ddi_metric]\n",
    "cornac.Experiment(\n",
    "    eval_method=ratio_split,\n",
    "    models=[model],\n",
    "    metrics=eval_metrics,\n",
    "    user_based=True,\n",
    ").run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa18af-41ee-4e0b-85f2-621db2c9772b",
   "metadata": {},
   "source": [
    "Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbe7c913-08ff-4129-b303-3c63cef73eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CASE STUDY: Top-10 Recommendations =====\n",
      "\n",
      "Users with pretrained emb: 14930/15162\n",
      "Items with pretrained emb: 457/1149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cb1dd9cfda419093564012f051b353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient HADM_ID: 100003\n",
      "  Ground Truth Drugs: ['acetaminophen', 'chloraseptic throat spray', 'folic acid', 'furosemide', 'lactulose', 'lidocaine', 'magnesium sulfate', 'nadolol', 'sarna lotion', 'sodium chloride', 'spironolactone', 'terbinafine 1 cream', 'thiamine']\n",
      "  Top-10 Recommendations:\n",
      "     1. sodium chloride (4.6272) \n",
      "     2. acetaminophen (4.4913) \n",
      "     3. heparin (4.4583) \n",
      "     4. docusate sodium (4.1799) \n",
      "     5. insulin sliding scale (4.1250) \n",
      "     6. metoprolol (4.0610) \n",
      "     7. potassium chloride (3.9449) \n",
      "     8. pantoprazole (3.9134) \n",
      "     9. morphine (3.8939) \n",
      "    10. senna (3.8594) \n",
      "------------------------------------------------------------\n",
      "Patient HADM_ID: 100009\n",
      "  Ground Truth Drugs: ['fenofibrate', 'acetaminophen', 'aspirin', 'atenolol', 'bisacodyl', 'calcium carbonate', 'cephalexin', 'chlorhexidine gluconate', 'dextrose 50', 'docusate sodium', 'sodium citrate', 'ezetimibe', 'furosemide', 'glucagon', 'glycopyrrolate', 'insulin sliding scale', 'insulin glargine', 'insulin human nph', 'ketorolac', 'lisinopril', 'lorazepam', 'metoclopramide', 'metoprolol', 'milk of magnesia', 'morphine', 'multivitamins', 'mupirocin', 'neostigmine', 'potassium chloride', 'propofol', 'ranitidine', 'simvastatin', 'sodium chloride']\n",
      "  Top-10 Recommendations:\n",
      "     1. sodium chloride (4.5548) \n",
      "     2. acetaminophen (4.4249) \n",
      "     3. heparin (4.3935) \n",
      "     4. docusate sodium (4.1032) \n",
      "     5. insulin sliding scale (4.0499) \n",
      "     6. metoprolol (3.9960) \n",
      "     7. morphine (3.8974) \n",
      "     8. potassium chloride (3.8676) \n",
      "     9. pantoprazole (3.8561) \n",
      "    10. senna (3.7865) \n",
      "------------------------------------------------------------\n",
      "Patient HADM_ID: 100011\n",
      "  Ground Truth Drugs: ['acetaminophen', 'acetylcysteine', 'albuterol', 'aspirin', 'bacitracin', 'bisacodyl', 'calcium gluconate', 'chlorhexidine gluconate', 'dextrose 50', 'docusate sodium', 'sodium citrate', 'famotidine', 'fentanyl', 'glucagon', 'hydromorphone', 'haloperidol', 'heparin', 'hydralazine', 'ibuprofen', 'insulin sliding scale', 'ipratropium bromide neb', 'lorazepam', 'magnesium sulfate', 'mannitol', 'metoclopramide', 'metoprolol', 'morphine', 'oxycodone', 'phenytoin', 'potassium chloride', 'propofol', 'senna', 'sodium chloride', 'tetanusdiphtheria tox decavac', 'vecuronium bromide']\n",
      "  Top-10 Recommendations:\n",
      "     1. sodium chloride (4.7961) \n",
      "     2. acetaminophen (4.6271) \n",
      "     3. heparin (4.6037) \n",
      "     4. docusate sodium (4.2799) \n",
      "     5. insulin sliding scale (4.2231) \n",
      "     6. metoprolol (4.2081) \n",
      "     7. morphine (4.0761) \n",
      "     8. pantoprazole (4.0442) \n",
      "     9. potassium chloride (4.0303) \n",
      "    10. senna (3.9646) \n",
      "------------------------------------------------------------\n",
      "Patient HADM_ID: 100021\n",
      "  Ground Truth Drugs: ['acetaminophen', 'aspirin', 'benztropine mesylate', 'calcium carbonate', 'calcium gluconate', 'diazepam', 'diltiazem', 'docusate sodium', 'enoxaparin sodium', 'famotidine', 'fentanyl', 'flumazenil', 'folic acid', 'hydromorphone', 'haloperidol', 'heparin', 'ibuprofen', 'insulin sliding scale', 'lactulose', 'lidocaine', 'lorazepam', 'metoprolol', 'morphine', 'multivitamins', 'neutraphos', 'nicotine', 'olanzapine', 'potassium chloride', 'rifaximin', 'senna', 'sodium chloride', 'trimethoprim', 'thiamine', 'trazodone']\n",
      "  Top-10 Recommendations:\n",
      "     1. sodium chloride (4.7213) \n",
      "     2. acetaminophen (4.5580) \n",
      "     3. heparin (4.5330) \n",
      "     4. docusate sodium (4.1994) \n",
      "     5. insulin sliding scale (4.1450) \n",
      "     6. metoprolol (4.1168) \n",
      "     7. morphine (3.9760) \n",
      "     8. potassium chloride (3.9599) \n",
      "     9. pantoprazole (3.9596) \n",
      "    10. furosemide (3.8988) \n",
      "------------------------------------------------------------\n",
      "Patient HADM_ID: 100036\n",
      "  Ground Truth Drugs: ['acetaminophen', 'aspirin', 'atorvastatin', 'bisacodyl', 'calcium gluconate', 'chlorhexidine gluconate', 'ofloxacin', 'dextrose 50', 'docusate sodium', 'sodium citrate', 'enoxaparin sodium', 'furosemide', 'glycopyrrolate', 'hydromorphone', 'hydralazine', 'insulin sliding scale', 'magnesium sulfate', 'metoclopramide', 'metoprolol', 'milk of magnesia', 'morphine', 'neostigmine', 'potassium chloride', 'propofol', 'ranitidine', 'sodium bicarbonate', 'sodium chloride', 'sucralfate', 'tramadol', 'warfarin']\n",
      "  Top-10 Recommendations:\n",
      "     1. sodium chloride (4.6702) \n",
      "     2. acetaminophen (4.5134) \n",
      "     3. heparin (4.5013) \n",
      "     4. docusate sodium (4.1699) \n",
      "     5. insulin sliding scale (4.1141) \n",
      "     6. metoprolol (4.0970) \n",
      "     7. morphine (3.9578) \n",
      "     8. pantoprazole (3.9380) \n",
      "     9. potassium chloride (3.9365) \n",
      "    10. senna (3.8808) \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Step 0: Pick 5 Patients -------------------\n",
    "case_patients = ratings_df[\"user\"].unique()[:5]  # first 5 unique patients\n",
    "print(\"\\n===== CASE STUDY: Top-10 Recommendations =====\\n\")\n",
    "\n",
    "# ------------------- Step 1: Prepare Train Set -------------------\n",
    "# Using all data as \"train\" for this example (no CV)\n",
    "train_set = cornac_data\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_set)\n",
    "\n",
    "# ------------------- Step 2: Generate Top-10 Recommendations -------------------\n",
    "for pid in case_patients:\n",
    "    if pid not in uid_map:\n",
    "        continue  # skip if patient not mapped\n",
    "\n",
    "    internal_uid = uid_map[pid]\n",
    "\n",
    "    # Ground-truth drugs for this patient\n",
    "    gt_drugs = ratings_df.loc[ratings_df[\"user\"] == pid, \"matched_generic\"].unique().tolist()\n",
    "\n",
    "    # Candidate items = all items\n",
    "    all_items = list(iid_map.keys())\n",
    "    item_indices = [iid_map[drug] for drug in all_items]\n",
    "\n",
    "    # Get scores for all items (fixed matrix multiplication)\n",
    "    item_factor_subset = model.i_factors[item_indices]  # shape: (num_items, k)\n",
    "    scores = model.u_factors[internal_uid] @ item_factor_subset.T + model.i_biases[item_indices]\n",
    "\n",
    "    # Rank by score and take Top-10\n",
    "    top10_idx = np.argsort(scores)[::-1][:10]\n",
    "    top10_drugs = [(all_items[i], scores[i]) for i in top10_idx]\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Patient HADM_ID: {pid}\")\n",
    "    print(f\"  Ground Truth Drugs: {gt_drugs}\")\n",
    "    print(\"  Top-10 Recommendations:\")\n",
    "    for rank, (drug, score) in enumerate(top10_drugs, 1):\n",
    "        marker = \"\" if drug in gt_drugs else \"\"\n",
    "        print(f\"    {rank:2d}. {drug} ({score:.4f}) {marker}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf568f4-c862-4958-b330-4b32e37c0f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
